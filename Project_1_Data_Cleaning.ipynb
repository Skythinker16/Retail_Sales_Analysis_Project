{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "8c8d3a73-3c03-481b-b87d-88b5bdb2bfa7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Raw Dataset Shape: (1000, 9)\n",
      "Raw Dataset Columns: ['Transaction ID', 'Date', 'Customer ID', 'Gender', 'Age', 'Product Category', 'Quantity', 'Price per Unit', 'Total Amount']\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from datetime import datetime\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Load raw dataset from fixed path(kaggle Link -https://www.kaggle.com/code/ahmdayman/retail-sales-dataset)\n",
    "raw_data_path = r\"C:\\Users\\SKY\\Desktop\\JOB prep\\Project-1-Retail-Sales-Analysis\\Data\\retail_sales_dataset.csv\"\n",
    "df = pd.read_csv(raw_data_path)\n",
    "\n",
    "print(\"Raw Dataset Shape:\", df.shape)\n",
    "print(\"Raw Dataset Columns:\", list(df.columns))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "2e751077-5205-46c6-8525-79bc7ab049a3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== DATA QUALITY ASSESSMENT ===\n",
      "Total Rows: 1000\n",
      "Total Columns: 9\n",
      "\n",
      "Missing Values:\n",
      "Transaction ID      0\n",
      "Date                0\n",
      "Customer ID         0\n",
      "Gender              0\n",
      "Age                 0\n",
      "Product Category    0\n",
      "Quantity            0\n",
      "Price per Unit      0\n",
      "Total Amount        0\n",
      "dtype: int64\n",
      "\n",
      "Duplicate Rows: 0\n",
      "Unique Transaction IDs: 1000\n"
     ]
    }
   ],
   "source": [
    "# Data Quality Assessment\n",
    "print(\"=== DATA QUALITY ASSESSMENT ===\")\n",
    "print(f\"Total Rows: {len(df)}\")\n",
    "print(f\"Total Columns: {len(df.columns)}\")\n",
    "print(\"\\nMissing Values:\")\n",
    "print(df.isnull().sum())\n",
    "print(f\"\\nDuplicate Rows: {df.duplicated().sum()}\")\n",
    "print(f\"Unique Transaction IDs: {df['Transaction ID'].nunique()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "1917d9d0-7229-4b36-8062-87994691ae45",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "New Column Names: ['transaction_id', 'date', 'customer_id', 'gender', 'age', 'product_category', 'quantity', 'price_per_unit', 'total_amount']\n",
      "Date Range: 2023-01-01 00:00:00 to 2024-01-01 00:00:00\n",
      "\n",
      "Product Categories: ['BEAUTY' 'CLOTHING' 'ELECTRONICS']\n",
      "Gender Values: ['MALE' 'FEMALE']\n"
     ]
    }
   ],
   "source": [
    "# Data Type Conversions and Cleaning\n",
    "df_clean = df.copy()\n",
    "\n",
    "# 1. Standardize column names (replace spaces with underscores, lowercase)\n",
    "df_clean.columns = [col.lower().replace(' ', '_') for col in df_clean.columns]\n",
    "print(\"New Column Names:\", list(df_clean.columns))\n",
    "\n",
    "# 2. Convert date column to datetime\n",
    "df_clean['date'] = pd.to_datetime(df_clean['date'])\n",
    "print(f\"Date Range: {df_clean['date'].min()} to {df_clean['date'].max()}\")\n",
    "\n",
    "# 3. Standardize categorical data\n",
    "df_clean['gender'] = df_clean['gender'].str.upper()\n",
    "df_clean['product_category'] = df_clean['product_category'].str.upper()\n",
    "\n",
    "print(\"\\nProduct Categories:\", df_clean['product_category'].unique())\n",
    "print(\"Gender Values:\", df_clean['gender'].unique())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "e882011f-d6d3-4350-9a1b-d54455a63ec6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Derived fields added. New shape: (1000, 21)\n"
     ]
    }
   ],
   "source": [
    "# 4. Create derived fields for analysis\n",
    "df_clean['year'] = df_clean['date'].dt.year\n",
    "df_clean['month'] = df_clean['date'].dt.month\n",
    "df_clean['quarter'] = df_clean['date'].dt.quarter\n",
    "df_clean['day_of_week'] = df_clean['date'].dt.day_name()\n",
    "df_clean['month_name'] = df_clean['date'].dt.month_name()\n",
    "df_clean['is_weekend'] = df_clean['date'].dt.weekday >= 5\n",
    "\n",
    "# Revenue and profit calculations (assuming cost structure)\n",
    "df_clean['revenue'] = df_clean['total_amount']  # Total amount is revenue\n",
    "df_clean['unit_cost'] = df_clean['price_per_unit'] * 0.6  # Assume 40% margin\n",
    "df_clean['total_cost'] = df_clean['unit_cost'] * df_clean['quantity']\n",
    "df_clean['profit'] = df_clean['revenue'] - df_clean['total_cost']\n",
    "df_clean['profit_margin'] = df_clean['profit'] / df_clean['revenue']\n",
    "\n",
    "# Age group segmentation\n",
    "bins = [0, 25, 35, 45, 55, 100]\n",
    "labels = ['18-25', '26-35', '36-45', '46-55', '56+']\n",
    "df_clean['age_group'] = pd.cut(df_clean['age'], bins=bins, labels=labels, right=False)\n",
    "\n",
    "print(f\"\\nDerived fields added. New shape: {df_clean.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "f0294763-1b49-4060-825c-4cd4c488baf1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== DATA VALIDATION ===\n",
      "Total Amount validation: PASSED\n",
      "Negative value checks: {'quantity': 0, 'price_per_unit': 0, 'total_amount': 0, 'profit': 0}\n",
      "Age outliers (< 18 or > 100): 0\n",
      "\n",
      "Final cleaned dataset shape: (1000, 21)\n"
     ]
    }
   ],
   "source": [
    "# 5. Data validation checks\n",
    "print(\"=== DATA VALIDATION ===\")\n",
    "\n",
    "# Check total amount calculation\n",
    "calculated_total = df_clean['quantity'] * df_clean['price_per_unit']\n",
    "validation_check = (df_clean['total_amount'] == calculated_total).all()\n",
    "print(f\"Total Amount validation: {'PASSED' if validation_check else 'FAILED'}\")\n",
    "\n",
    "# Check for negative values\n",
    "negative_checks = {\n",
    "    'quantity': (df_clean['quantity'] < 0).sum(),\n",
    "    'price_per_unit': (df_clean['price_per_unit'] < 0).sum(), \n",
    "    'total_amount': (df_clean['total_amount'] < 0).sum(),\n",
    "    'profit': (df_clean['profit'] < 0).sum()\n",
    "}\n",
    "print(\"Negative value checks:\", negative_checks)\n",
    "\n",
    "# Age validation\n",
    "age_issues = df_clean[(df_clean['age'] < 18) | (df_clean['age'] > 100)]\n",
    "print(f\"Age outliers (< 18 or > 100): {len(age_issues)}\")\n",
    "\n",
    "print(\"\\nFinal cleaned dataset shape:\", df_clean.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "3b9ffe75-2cd4-472c-8c20-e10f45810d25",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cleaned dataset saved to: C:\\Users\\SKY\\Desktop\\JOB prep\\Project-1-Retail-Sales-Analysis\\Data\\retail_sales_cleaned.csv\n",
      "\n",
      "Sample of cleaned data:\n",
      "   transaction_id       date customer_id  gender  age product_category  \\\n",
      "0               1 2023-11-24     CUST001    MALE   34           BEAUTY   \n",
      "1               2 2023-02-27     CUST002  FEMALE   26         CLOTHING   \n",
      "2               3 2023-01-13     CUST003    MALE   50      ELECTRONICS   \n",
      "3               4 2023-05-21     CUST004    MALE   37         CLOTHING   \n",
      "4               5 2023-05-06     CUST005    MALE   30           BEAUTY   \n",
      "\n",
      "   quantity  price_per_unit  total_amount  year  ...  quarter  day_of_week  \\\n",
      "0         3              50           150  2023  ...        4       Friday   \n",
      "1         2             500          1000  2023  ...        1       Monday   \n",
      "2         1              30            30  2023  ...        1       Friday   \n",
      "3         1             500           500  2023  ...        2       Sunday   \n",
      "4         2              50           100  2023  ...        2     Saturday   \n",
      "\n",
      "  month_name is_weekend  revenue  unit_cost  total_cost  profit  \\\n",
      "0   November      False      150       30.0        90.0    60.0   \n",
      "1   February      False     1000      300.0       600.0   400.0   \n",
      "2    January      False       30       18.0        18.0    12.0   \n",
      "3        May       True      500      300.0       300.0   200.0   \n",
      "4        May       True      100       30.0        60.0    40.0   \n",
      "\n",
      "   profit_margin  age_group  \n",
      "0            0.4      26-35  \n",
      "1            0.4      26-35  \n",
      "2            0.4      46-55  \n",
      "3            0.4      36-45  \n",
      "4            0.4      26-35  \n",
      "\n",
      "[5 rows x 21 columns]\n"
     ]
    }
   ],
   "source": [
    "# 6. Save cleaned dataset\n",
    "cleaned_data_path = r\"C:\\Users\\SKY\\Desktop\\JOB prep\\Project-1-Retail-Sales-Analysis\\Data\\retail_sales_cleaned.csv\"\n",
    "df_clean.to_csv(cleaned_data_path, index=False)\n",
    "print(f\"Cleaned dataset saved to: {cleaned_data_path}\")\n",
    "\n",
    "# Display sample of cleaned data\n",
    "print(\"\\nSample of cleaned data:\")\n",
    "print(df_clean.head())"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:base] *",
   "language": "python",
   "name": "conda-base-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
